{
  "_args": [
    [
      {
        "raw": "ava",
        "scope": null,
        "escapedName": "ava",
        "name": "ava",
        "rawSpec": "",
        "spec": "latest",
        "type": "tag"
      },
      "/Users/sotongo/Code/productivity/vendor/oburatongoi/productivity"
    ]
  ],
  "_from": "ava@latest",
  "_id": "ava@0.19.1",
  "_inCache": true,
  "_location": "/ava",
  "_nodeVersion": "7.8.0",
  "_npmOperationalInternal": {
    "host": "packages-12-west.internal.npmjs.com",
    "tmp": "tmp/ava-0.19.1.tgz_1491813236525_0.9140785234048963"
  },
  "_npmUser": {
    "name": "novemberborn",
    "email": "mark@novemberborn.net"
  },
  "_npmVersion": "4.5.0",
  "_phantomChildren": {
    "argparse": "1.0.9",
    "array-union": "1.0.2",
    "brace-expansion": "1.1.6",
    "fs.realpath": "1.0.0",
    "inflight": "1.0.6",
    "inherits": "2.0.3",
    "once": "1.3.3",
    "path-is-absolute": "1.0.1",
    "pify": "2.3.0",
    "pinkie-promise": "2.0.1"
  },
  "_requested": {
    "raw": "ava",
    "scope": null,
    "escapedName": "ava",
    "name": "ava",
    "rawSpec": "",
    "spec": "latest",
    "type": "tag"
  },
  "_requiredBy": [
    "#DEV:/",
    "#USER"
  ],
  "_resolved": "https://registry.npmjs.org/ava/-/ava-0.19.1.tgz",
  "_shasum": "43dd82435ad19b3980ffca2488f05daab940b273",
  "_shrinkwrap": null,
  "_spec": "ava",
  "_where": "/Users/sotongo/Code/productivity/vendor/oburatongoi/productivity",
  "author": {
    "name": "Sindre Sorhus",
    "email": "sindresorhus@gmail.com",
    "url": "sindresorhus.com"
  },
  "bin": {
    "ava": "cli.js"
  },
  "bugs": {
    "url": "https://github.com/avajs/ava/issues"
  },
  "dependencies": {
    "@ava/babel-preset-stage-4": "^1.0.0",
    "@ava/babel-preset-transform-test-files": "^3.0.0",
    "@ava/pretty-format": "^1.1.0",
    "arr-flatten": "^1.0.1",
    "array-union": "^1.0.1",
    "array-uniq": "^1.0.2",
    "arrify": "^1.0.0",
    "auto-bind": "^1.1.0",
    "ava-init": "^0.2.0",
    "babel-code-frame": "^6.16.0",
    "babel-core": "^6.17.0",
    "bluebird": "^3.0.0",
    "caching-transform": "^1.0.0",
    "chalk": "^1.0.0",
    "chokidar": "^1.4.2",
    "clean-stack": "^1.1.1",
    "clean-yaml-object": "^0.1.0",
    "cli-cursor": "^2.1.0",
    "cli-spinners": "^1.0.0",
    "cli-truncate": "^1.0.0",
    "co-with-promise": "^4.6.0",
    "code-excerpt": "^2.1.0",
    "common-path-prefix": "^1.0.0",
    "convert-source-map": "^1.2.0",
    "core-assert": "^0.2.0",
    "currently-unhandled": "^0.4.1",
    "debug": "^2.2.0",
    "diff": "^3.0.1",
    "diff-match-patch": "^1.0.0",
    "dot-prop": "^4.1.0",
    "empower-core": "^0.6.1",
    "equal-length": "^1.0.0",
    "figures": "^2.0.0",
    "find-cache-dir": "^0.1.1",
    "fn-name": "^2.0.0",
    "get-port": "^3.0.0",
    "globby": "^6.0.0",
    "has-flag": "^2.0.0",
    "hullabaloo-config-manager": "^1.0.0",
    "ignore-by-default": "^1.0.0",
    "indent-string": "^3.0.0",
    "is-ci": "^1.0.7",
    "is-generator-fn": "^1.0.0",
    "is-obj": "^1.0.0",
    "is-observable": "^0.2.0",
    "is-promise": "^2.1.0",
    "jest-diff": "19.0.0",
    "jest-snapshot": "19.0.2",
    "js-yaml": "^3.8.2",
    "last-line-stream": "^1.0.0",
    "lodash.debounce": "^4.0.3",
    "lodash.difference": "^4.3.0",
    "lodash.flatten": "^4.2.0",
    "lodash.isequal": "^4.5.0",
    "loud-rejection": "^1.2.0",
    "matcher": "^0.1.1",
    "md5-hex": "^2.0.0",
    "meow": "^3.7.0",
    "mkdirp": "^0.5.1",
    "ms": "^0.7.1",
    "multimatch": "^2.1.0",
    "observable-to-promise": "^0.5.0",
    "option-chain": "^0.1.0",
    "package-hash": "^2.0.0",
    "pkg-conf": "^2.0.0",
    "plur": "^2.0.0",
    "pretty-ms": "^2.0.0",
    "require-precompiled": "^0.1.0",
    "resolve-cwd": "^1.0.0",
    "slash": "^1.0.0",
    "source-map-support": "^0.4.0",
    "stack-utils": "^1.0.0",
    "strip-ansi": "^3.0.1",
    "strip-bom-buf": "^1.0.0",
    "supports-color": "^3.2.3",
    "time-require": "^0.1.2",
    "unique-temp-dir": "^1.0.0",
    "update-notifier": "^2.1.0"
  },
  "description": "Futuristic test runner ðŸš€",
  "devDependencies": {
    "babel-preset-react": "^6.5.0",
    "cli-table2": "^0.2.0",
    "coveralls": "^2.11.4",
    "delay": "^1.3.0",
    "execa": "^0.6.0",
    "flow-bin": "^0.42.0",
    "get-stream": "^3.0.0",
    "git-branch": "^0.3.0",
    "has-ansi": "^2.0.0",
    "inquirer": "^3.0.5",
    "is-array-sorted": "^1.0.0",
    "lolex": "^1.4.0",
    "nyc": "^10.0.0",
    "proxyquire": "^1.7.4",
    "rimraf": "^2.5.0",
    "signal-exit": "^3.0.0",
    "sinon": "^2.0.0",
    "source-map-fixtures": "^2.1.0",
    "tap": "^10.0.0",
    "temp-write": "^3.1.0",
    "touch": "^1.0.0",
    "typescript": "^2.2.2",
    "xo": "^0.18.0",
    "zen-observable": "^0.5.1"
  },
  "directories": {},
  "dist": {
    "shasum": "43dd82435ad19b3980ffca2488f05daab940b273",
    "tarball": "https://registry.npmjs.org/ava/-/ava-0.19.1.tgz"
  },
  "engines": {
    "node": ">=4"
  },
  "files": [
    "lib",
    "*.js",
    "*.js.flow",
    "types/generated.d.ts"
  ],
  "gitHead": "4cc3403b4878e0e32c8d1a2e95874223fe4cdc29",
  "homepage": "https://ava.li",
  "keywords": [
    "test",
    "runner",
    "ava",
    "concurrent",
    "parallel",
    "fast",
    "tape",
    "tap",
    "jest",
    "mocha",
    "qunit",
    "jasmine",
    "testing",
    "tdd",
    "cli-app",
    "cli",
    "assert",
    "assertion",
    "futuristic",
    "promise",
    "promises",
    "async",
    "function",
    "await",
    "generator",
    "generators",
    "yield",
    "observable",
    "observables"
  ],
  "license": "MIT",
  "maintainers": [
    {
      "name": "Vadim Demedes",
      "email": "vdemedes@gmail.com",
      "url": "github.com/vadimdemedes"
    },
    {
      "name": "James Talmage",
      "email": "james@talmage.io",
      "url": "github.com/jamestalmage"
    },
    {
      "name": "Mark Wubben",
      "email": "mark@novemberborn.net",
      "url": "novemberborn.net"
    },
    {
      "name": "Juan Soto",
      "email": "juan@juansoto.me",
      "url": "juansoto.me"
    },
    {
      "name": "Jeroen Engels",
      "email": "jfm.engels@gmail.com",
      "url": "github.com/jfmengels"
    }
  ],
  "name": "ava",
  "nyc": {
    "reporter": [
      "html",
      "lcov",
      "text"
    ]
  },
  "optionalDependencies": {},
  "readme": "# [![AVA](media/header.png)](https://ava.li)\n\n> Futuristic test runner\n\n[![Build Status: Linux](https://travis-ci.org/avajs/ava.svg?branch=master)](https://travis-ci.org/avajs/ava) [![Build status: Windows](https://ci.appveyor.com/api/projects/status/e7v91mu2m5x48ehx/branch/master?svg=true)](https://ci.appveyor.com/project/ava/ava/branch/master) [![Coverage Status](https://coveralls.io/repos/github/avajs/ava/badge.svg?branch=master)](https://coveralls.io/github/avajs/ava?branch=master) [![Dependency Status](https://dependencyci.com/github/avajs/ava/badge)](https://dependencyci.com/github/avajs/ava) [![XO code style](https://img.shields.io/badge/code_style-XO-5ed9c7.svg)](https://github.com/sindresorhus/xo) [![Gitter](https://badges.gitter.im/join_chat.svg)](https://gitter.im/avajs/ava)\n\nEven though JavaScript is single-threaded, IO in Node.js can happen in parallel due to its async nature. AVA takes advantage of this and runs your tests concurrently, which is especially beneficial for IO heavy tests. In addition, test files are run in parallel as separate processes, giving you even better performance and an isolated environment for each test file. [Switching](https://github.com/sindresorhus/pageres/commit/663be15acb3dd2eb0f71b1956ef28c2cd3fdeed0) from Mocha to AVA in Pageres brought the test time down from 31 to 11 seconds. Having tests run concurrently forces you to write atomic tests, meaning tests don't depend on global state or the state of other tests, which is a great thing!\n\n![](media/screenshot-mini-reporter.gif)\n\n*Read our [contributing guide](contributing.md) if you're looking to contribute (issues/PRs/etc).*\n\nFollow the [AVA Twitter account](https://twitter.com/ava__js) for updates.\n\nTranslations: [EspaÃ±ol](https://github.com/avajs/ava-docs/blob/master/es_ES/readme.md), [FranÃ§ais](https://github.com/avajs/ava-docs/blob/master/fr_FR/readme.md), [Italiano](https://github.com/avajs/ava-docs/blob/master/it_IT/readme.md), [æ—¥æœ¬èªž](https://github.com/avajs/ava-docs/blob/master/ja_JP/readme.md), [í•œêµ­ì–´](https://github.com/avajs/ava-docs/blob/master/ko_KR/readme.md), [PortuguÃªs](https://github.com/avajs/ava-docs/blob/master/pt_BR/readme.md), [Ð ÑƒÑÑÐºÐ¸Ð¹](https://github.com/avajs/ava-docs/blob/master/ru_RU/readme.md), [ç®€ä½“ä¸­æ–‡](https://github.com/avajs/ava-docs/blob/master/zh_CN/readme.md)\n\n\n## Contents\n\n- [Usage](#usage)\n- [CLI Usage](#cli)\n- [Debugging](#debugging)\n- [Reporters](#reporters)\n- [Configuration](#configuration)\n- [Documentation](#documentation)\n- [API](#api)\n- [Assertions](#assertions)\n- [Snapshot testing](#snapshot-testing)\n- [Tips](#tips)\n- [FAQ](#faq)\n- [Recipes](#recipes)\n- [Support](#support)\n- [Related](#related)\n- [Links](#links)\n- [Team](#team)\n\n\n## Why AVA?\n\n- Minimal and fast\n- Simple test syntax\n- Runs tests concurrently\n- Enforces writing atomic tests\n- No implicit globals\n- Includes TypeScript & Flow type definitions\n- [Magic assert](#magic-assert)\n- [Isolated environment for each test file](#process-isolation)\n- [Write your tests in ES2017](#es2017-support)\n- [Promise support](#promise-support)\n- [Generator function support](#generator-function-support)\n- [Async function support](#async-function-support)\n- [Observable support](#observable-support)\n- [Enhanced assertion messages](#enhanced-assertion-messages)\n- [TAP reporter](#tap-reporter)\n- [Automatic migration from other test runners](https://github.com/avajs/ava-codemods#migrating-to-ava)\n\n\n## Test syntax\n\n```js\nimport test from 'ava';\n\ntest(t => {\n\tt.deepEqual([1, 2], [1, 2]);\n});\n```\n\n## Usage\n\n### Add AVA to your project\n\nInstall AVA globally and run it with `--init` to add AVA to your `package.json`. [Yarn](https://yarnpkg.com/) currently provides significant speed improvements over npm during the installation process. Consider [using Yarn](https://yarnpkg.com/en/docs/install) if the installation is too slow for your needs.\n\n\n```console\n$ yarn global add ava\n$ ava --init\n```\n\nIf you prefer using npm:\n\n```console\n$ npm install --global ava\n$ ava --init\n```\n\nYour `package.json` will then look like this:\n\n```json\n{\n  \"name\": \"awesome-package\",\n  \"scripts\": {\n    \"test\": \"ava\"\n  },\n  \"devDependencies\": {\n    \"ava\": \"^0.18.0\"\n  }\n}\n```\n\nAny arguments passed after `--init` are added as config to `package.json`.\n\n#### Manual installation\n\nYou can also install AVA directly:\n\n```console\n$ yarn add --dev ava\n```\n\nAlternatively using npm:\n\n```console\n$ npm install --save-dev ava\n```\n\nYou'll have to configure the `test` script in your `package.json` to use `ava` (see above).\n\n### Create your test file\n\nCreate a file named `test.js` in the project root directory:\n\n```js\nimport test from 'ava';\n\ntest('foo', t => {\n\tt.pass();\n});\n\ntest('bar', async t => {\n\tconst bar = Promise.resolve('bar');\n\n\tt.is(await bar, 'bar');\n});\n```\n\n### Run it\n\n```console\n$ npm test\n```\n\n### Watch it\n\n```console\n$ npm test -- --watch\n```\n\nAVA comes with an intelligent watch mode. [Learn more in its recipe](docs/recipes/watch-mode.md).\n\n## CLI\n\n```console\n$ ava --help\n\n  Usage\n    ava [<file|directory|glob> ...]\n\n  Options\n    --init                  Add AVA to your project\n    --fail-fast             Stop after first test failure\n    --serial, -s            Run tests serially\n    --tap, -t               Generate TAP output\n    --verbose, -v           Enable verbose output\n    --no-cache              Disable the transpiler cache\n    --no-power-assert       Disable Power Assert\n    --color                 Force color output\n    --no-color              Disable color output\n    --match, -m             Only run tests with matching title (Can be repeated)\n    --watch, -w             Re-run tests when tests and source files change\n    --timeout, -T           Set global timeout\n    --concurrency, -c       Maximum number of test files running at the same time (EXPERIMENTAL)\n    --update-snapshots, -u  Update snapshots\n\n  Examples\n    ava\n    ava test.js test2.js\n    ava test-*.js\n    ava test\n    ava --init\n    ava --init foo.js\n\n  Default patterns when no arguments:\n  test.js test-*.js test/**/*.js **/__tests__/**/*.js **/*.test.js\n```\n\n*Note that the CLI will use your local install of AVA when available, even when run globally.*\n\nDirectories are recursed, with all `*.js` files being treated as test files. Directories named `fixtures`, `helpers` and `node_modules` are *always* ignored. So are files starting with `_` which allows you to place helpers in the same directory as your test files.\n\nWhen using `npm test`, you can pass positional arguments directly `npm test test2.js`, but flags needs to be passed like `npm test -- --verbose`.\n\n\n## Debugging\n\nAVA runs tests in child processes, so to debug tests, you need to do this workaround:\n\n```console\n$ node --inspect node_modules/ava/profile.js some/test/file.js\n```\n\n### Debugger-specific tips\n\n- [Chrome DevTools](docs/recipes/debugging-with-chrome-devtools.md)\n- [WebStorm](docs/recipes/debugging-with-webstorm.md)\n\n\n## Reporters\n\n### Mini-reporter\n\nThe mini-reporter is the default reporter.\n\n<img src=\"media/screenshot-mini-reporter.gif\" width=\"460\">\n\n### Verbose reporter\n\nUse the `--verbose` flag to enable the verbose reporter. This is always used in CI environments unless the [TAP reporter](#tap-reporter) is enabled.\n\n<img src=\"media/screenshot.png\" width=\"150\">\n\n### TAP reporter\n\nAVA supports the TAP format and thus is compatible with [any TAP reporter](https://github.com/sindresorhus/awesome-tap#reporters). Use the `--tap` flag to enable TAP output.\n\n```console\n$ ava --tap | tap-nyan\n```\n\n<img src=\"media/tap-output.png\" width=\"398\">\n\nPlease note that the TAP reporter is unavailable when using [watch mode](#watch-it).\n\n### Magic assert\n\nAVA adds code excerpts and clean diffs for actual and expected values. If values in the assertion are objects or arrays, only a diff is displayed, to remove the noise and focus on the problem. The diff is syntax-highlighted too! If you are comparing strings, both single and multi line, AVA displays a different kind of output, highlighting the added or missing characters.\n\n![](media/magic-assert-combined.png)\n\n### Clean stack traces\n\nAVA automatically removes unrelated lines in stack traces, allowing you to find the source of an error much faster, as seen above.\n\n\n## Configuration\n\nAll of the CLI options can be configured in the `ava` section of your `package.json`. This allows you to modify the default behavior of the `ava` command, so you don't have to repeatedly type the same options on the command prompt.\n\n```json\n{\n  \"ava\": {\n    \"files\": [\n      \"my-test-folder/*.js\",\n      \"!**/not-this-file.js\"\n    ],\n    \"source\": [\n      \"**/*.{js,jsx}\",\n      \"!dist/**/*\"\n    ],\n    \"match\": [\n      \"*oo\",\n      \"!foo\"\n    ],\n    \"concurrency\": 5,\n    \"failFast\": true,\n    \"failWithoutAssertions\": false,\n    \"tap\": true,\n    \"powerAssert\": false,\n    \"require\": [\n      \"babel-register\"\n    ],\n    \"babel\": \"inherit\"\n  }\n}\n```\n\nArguments passed to the CLI will always take precedence over the configuration in `package.json`.\n\nSee the [ES2017 support](#es2017-support) section for details on the `babel` option.\n\n## Documentation\n\nTests are run concurrently. You can specify synchronous and asynchronous tests. Tests are considered synchronous unless you return a promise or [observable](https://github.com/zenparsing/zen-observable).\n\nWe *highly* recommend the use of [async functions](#async-function-support). They make asynchronous code concise and readable, and they implicitly return a promise so you don't have to.\n\nIf you're unable to use promises or observables, you may enable \"callback mode\" by defining your test with `test.cb([title], fn)`. Tests declared this way **must** be manually ended with `t.end()`. This mode is mainly intended for testing callback-style APIs. However, we would strongly recommend [promisifying](https://github.com/sindresorhus/pify) callback-style APIs instead of using \"callback mode\", as this results in more correct and readable tests.\n\nYou must define all tests synchronously. They can't be defined inside `setTimeout`, `setImmediate`, etc.\n\nAVA tries to run test files with their current working directory set to the directory that contains your `package.json` file.\n\n### Creating tests\n\nTo create a test you call the `test` function you imported from AVA. Provide the optional title and implementation function. The function will be called when your test is run. It's passed an [execution object](#t) as its first argument.\n\n**Note:** In order for the [enhanced assertion messages](#enhanced-assertion-messages) to behave correctly, the first argument **must** be named `t`.\n\n```js\nimport test from 'ava';\n\ntest('my passing test', t => {\n\tt.pass();\n});\n```\n\n#### Titles\n\nTitles are optional, meaning you can do:\n\n```js\ntest(t => {\n\tt.pass();\n});\n```\n\nIt's recommended to provide test titles if you have more than one test.\n\nIf you haven't provided a test title, but the implementation is a named function, that name will be used as the test title:\n\n```js\ntest(function name(t) {\n\tt.pass();\n});\n```\n\n### Assertion planning\n\nAssertion plans ensure tests only pass when a specific number of assertions have been executed. They'll help you catch cases where tests exit too early. They'll also cause tests to fail if too many assertions are executed, which can be useful if you have assertions inside callbacks or loops.\n\nIf you do not specify an assertion plan, your test will still fail if no assertions are executed. Set the `failWithoutAssertions` option to `false` in AVA's [`package.json` configuration](#configuration) to disable this behavior.\n\nNote that, unlike [`tap`](https://www.npmjs.com/package/tap) and [`tape`](https://www.npmjs.com/package/tape), AVA does *not* automatically end a test when the planned assertion count is reached.\n\nThese examples will result in a passed test:\n\n```js\ntest(t => {\n\tt.plan(1);\n\n\treturn Promise.resolve(3).then(n => {\n\t\tt.is(n, 3);\n\t});\n});\n\ntest.cb(t => {\n\tt.plan(1);\n\n\tsomeAsyncFunction(() => {\n\t\tt.pass();\n\t\tt.end();\n\t});\n});\n```\n\nThese won't:\n\n```js\ntest(t => {\n\tt.plan(2);\n\n\tfor (let i = 0; i < 3; i++) {\n\t\tt.true(i < 3);\n\t}\n}); // Fails, 3 assertions are executed which is too many\n\ntest(t => {\n\tt.plan(1);\n\n\tsomeAsyncFunction(() => {\n\t\tt.pass();\n\t});\n}); // Fails, the test ends synchronously before the assertion is executed\n```\n\n### Running tests serially\n\nBy default tests are run concurrently, which is awesome. Sometimes though you have to write tests that cannot run concurrently.\n\nIn these rare cases you can use the `.serial` modifier. It will force those tests to run serially *before* the concurrent ones.\n\n```js\ntest.serial(t => {\n\tt.pass();\n});\n```\n\nNote that this only applies to tests within a particular test file. AVA will still run multiple tests files at the same time unless you pass the [`--serial` CLI flag](#cli).\n\n### Running specific tests\n\nDuring development it can be helpful to only run a few specific tests. This can be accomplished using the `.only` modifier:\n\n```js\ntest('will not be run', t => {\n\tt.fail();\n});\n\ntest.only('will be run', t => {\n\tt.pass();\n});\n```\n\n`.only` applies across all test files, so if you use it in one file, no tests from the other file will run.\n\n### Running tests with matching titles\n\nThe `--match` flag allows you to run just the tests that have a matching title. This is achieved with simple wildcard patterns. Patterns are case insensitive. See [`matcher`](https://github.com/sindresorhus/matcher) for more details.\n\nMatch titles ending with `foo`:\n\n```console\n$ ava --match='*foo'\n```\n\nMatch titles starting with `foo`:\n\n```console\n$ ava --match='foo*'\n```\n\nMatch titles containing `foo`:\n\n```console\n$ ava --match='*foo*'\n```\n\nMatch titles that are *exactly* `foo` (albeit case insensitively):\n\n```console\n$ ava --match='foo'\n```\n\nMatch titles not containing `foo`:\n\n```console\n$ ava --match='!*foo*'\n```\n\nMatch titles starting with `foo` and ending with `bar`:\n\n```console\n$ ava --match='foo*bar'\n```\n\nMatch titles starting with `foo` or ending with `bar`:\n\n```console\n$ ava --match='foo*' --match='*bar'\n```\n\nNote that a match pattern takes precedence over the `.only` modifier. Only tests with an explicit title are matched. Tests without titles or whose title is derived from the implementation function will be skipped when `--match` is used.\n\nHere's what happens when you run AVA with a match pattern of `*oo*` and the following tests:\n\n```js\ntest('foo will run', t => {\n\tt.pass();\n});\n\ntest('moo will also run', t => {\n\tt.pass();\n});\n\ntest.only('boo will run but not exclusively', t => {\n\tt.pass();\n});\n\n// Won't run, no title\ntest(function (t) {\n\tt.fail();\n});\n\n// Won't run, no explicit title\ntest(function foo(t) {\n\tt.fail();\n});\n```\n\n### Skipping tests\n\nSometimes failing tests can be hard to fix. You can tell AVA to skip these tests using the `.skip` modifier. They'll still be shown in the output (as having been skipped) but are never run.\n\n```js\ntest.skip('will not be run', t => {\n\tt.fail();\n});\n```\n\nYou must specify the implementation function.\n\n### Test placeholders (\"todo\")\n\nYou can use the `.todo` modifier when you're planning to write a test. Like skipped tests these placeholders are shown in the output. They only require a title; you cannot specify the implementation function.\n\n```js\ntest.todo('will think about writing this later');\n```\n\n### Failing tests\n\nYou can use the `.failing` modifier to document issues with your code that need to be fixed. Failing tests are run just like normal ones, but they are expected to fail, and will not break your build when they do. If a test marked as failing actually passes, it will be reported as an error and fail the build with a helpful message instructing you to remove the `.failing` modifier.\n\nThis allows you to merge `.failing` tests before a fix is implemented without breaking CI. This is a great way to recognize good bug report PR's with a commit credit, even if the reporter is unable to actually fix the problem.\n\n```js\n// See: github.com/user/repo/issues/1234\ntest.failing('demonstrate some bug', t => {\n\tt.fail(); // Test will count as passed\n});\n```\n\n### Before & after hooks\n\nAVA lets you register hooks that are run before and after your tests. This allows you to run setup and/or teardown code.\n\n`test.before()` registers a hook to be run before the first test in your test file. Similarly `test.after()` registers a hook to be run after the last test. Use `test.after.always()` to register a hook that will **always** run once your tests and other hooks complete. `.always()` hooks run regardless of whether there were earlier failures, so they are ideal for cleanup tasks. There are two exceptions to this however. If you use `--fail-fast` AVA will stop testing as soon as a failure occurs, and it won't run any hooks including the `.always()` hooks. Uncaught exceptions will crash your tests, possibly preventing `.always()` hooks from running.\n\n`test.beforeEach()` registers a hook to be run before each test in your test file. Similarly `test.afterEach()` a hook to be run after each test. Use `test.afterEach.always()` to register an after hook that is called even if other test hooks, or the test itself, fail. `.always()` hooks are ideal for cleanup tasks.\n\n**Note**: If the `--fail-fast` flag is specified, AVA will stop after the first test failure and the `.always` hook will **not** run.\n\nLike `test()` these methods take an optional title and a callback function. The title is shown if your hook fails to execute. The callback is called with an [execution object](#t).\n\n`before` hooks execute before `beforeEach` hooks. `afterEach` hooks execute before `after` hooks. Within their category the hooks execute in the order they were defined.\n\n```js\ntest.before(t => {\n\t// This runs before all tests\n});\n\ntest.before(t => {\n\t// This runs after the above, but before tests\n});\n\ntest.after('cleanup', t => {\n\t// This runs after all tests\n});\n\ntest.after.always('guaranteed cleanup', t => {\n\t// This will always run, regardless of earlier failures\n});\n\ntest.beforeEach(t => {\n\t// This runs before each test\n});\n\ntest.afterEach(t => {\n\t// This runs after each test\n});\n\ntest.afterEach.always(t => {\n\t// This runs after each test and other test hooks, even if they failed\n});\n\ntest(t => {\n\t// Regular test\n});\n```\n\nHooks can be synchronous or asynchronous, just like tests. To make a hook asynchronous return a promise or observable, use an async function, or enable callback mode via `test.cb.before()`, `test.cb.beforeEach()` etc.\n\n```js\ntest.before(async t => {\n\tawait promiseFn();\n});\n\ntest.after(t => {\n\treturn new Promise(/* ... */);\n});\n\ntest.cb.beforeEach(t => {\n\tsetTimeout(t.end);\n});\n\ntest.afterEach.cb(t => {\n\tsetTimeout(t.end);\n});\n```\n\nKeep in mind that the `beforeEach` and `afterEach` hooks run just before and after a test is run, and that by default tests run concurrently. If you need to set up global state for each test (like spying on `console.log` [for example](https://github.com/avajs/ava/issues/560)), you'll need to make sure the tests are [run serially](#running-tests-serially).\n\nRemember that AVA runs each test file in its own process. You may not have to clean up global state in a `after`-hook since that's only called right before the process exits.\n\n#### Test context\n\nThe `beforeEach` & `afterEach` hooks can share context with the test:\n\n```js\ntest.beforeEach(t => {\n\tt.context.data = generateUniqueData();\n});\n\ntest(t => {\n\tt.is(t.context.data + 'bar', 'foobar');\n});\n```\n\nThe context is not shared between tests, allowing you to set up data in a way where it will not risk leaking to other, subsequent tests. By default `t.context` is an object but you can reassign it:\n\n```js\ntest.beforeEach(t => {\n\tt.context = 'unicorn';\n});\n\ntest(t => {\n\tt.is(t.context, 'unicorn');\n});\n```\n\nContext sharing is *not* available to `before` and `after` hooks.\n\n### Chaining test modifiers\n\nYou can use the `.serial`, `.only` and `.skip` modifiers in any order, with `test`, `before`, `after`, `beforeEach` and `afterEach`. For example:\n\n```js\ntest.before.skip(...);\ntest.skip.after(...);\ntest.serial.only(...);\ntest.only.serial(...);\n```\n\nThis means you can temporarily add `.skip` or `.only` at the end of a test or hook definition without having to make any other changes.\n\n### Test macros\n\nAdditional arguments passed to the test declaration will be passed to the test implementation. This is useful for creating reusable test macros.\n\n```js\nfunction macro(t, input, expected) {\n\tt.is(eval(input), expected);\n}\n\ntest('2 + 2 === 4', macro, '2 + 2', 4);\ntest('2 * 3 === 6', macro, '2 * 3', 6);\n```\n\nYou can build the test title programmatically by attaching a `title` function to the macro:\n\n```js\nfunction macro(t, input, expected) {\n\tt.is(eval(input), expected);\n}\n\nmacro.title = (providedTitle, input, expected) => `${providedTitle} ${input} === ${expected}`.trim();\n\ntest(macro, '2 + 2', 4);\ntest(macro, '2 * 3', 6);\ntest('providedTitle', macro, '3 * 3', 9);\n```\n\nThe `providedTitle` argument defaults to an empty string if the user does not supply a string title. This allows for easy concatenation without having to worry about `null` / `undefined`. It is worth remembering that the empty string is considered a falsy value, so you can still use `if(providedTitle) {...}`.\n\nYou can also pass arrays of macro functions:\n\n```js\nconst safeEval = require('safe-eval');\n\nfunction evalMacro(t, input, expected) {\n\tt.is(eval(input), expected);\n}\n\nfunction safeEvalMacro(t, input, expected) {\n\tt.is(safeEval(input), expected);\n}\n\ntest([evalMacro, safeEvalMacro], '2 + 2', 4);\ntest([evalMacro, safeEvalMacro], '2 * 3', 6);\n```\n\nWe encourage you to use macros instead of building your own test generators ([here is an example](https://github.com/avajs/ava-codemods/blob/47073b5b58aa6f3fb24f98757be5d3f56218d160/test/ok-to-truthy.js#L7-L9) of code that should be replaced with a macro). Macros are designed to perform static analysis of your code, which can lead to better performance, IDE integration, and linter rules.\n\n### Custom assertions\n\nYou can use any assertion library instead of or in addition to the built-in one, provided it throws exceptions when the assertion fails.\n\nThis won't give you as nice an experience as you'd get with the [built-in assertions](#assertions) though, and you won't be able to use the [assertion planning](#assertion-planning) ([see #25](https://github.com/avajs/ava/issues/25)).\n\nYou'll have to configure AVA to not fail tests if no assertions are executed, because AVA can't tell if custom assertions pass. Set the `failWithoutAssertions` option to `false` in AVA's [`package.json` configuration](#configuration).\n\n```js\nimport assert from 'assert';\n\ntest(t => {\n\tassert(true);\n});\n```\n\n### ES2017 support\n\nAVA comes with built-in support for ES2017 through [Babel 6](https://babeljs.io). Just write your tests in ES2017. No extra setup needed. You can use any Babel version in your project. We use our own bundled Babel with our [`@ava/stage-4`](https://github.com/avajs/babel-preset-stage-4) preset, as well as [custom transforms](https://github.com/avajs/babel-preset-transform-test-files) for test and helper files.\n\nThe corresponding Babel config for AVA's setup is as follows:\n\n```json\n{\n  \"presets\": [\n    \"@ava/stage-4\",\n    \"@ava/transform-test-files\"\n  ]\n}\n```\n\nYou can customize how AVA transpiles the test files through the `babel` option in AVA's [`package.json` configuration](#configuration). For example to override the presets you can use:\n\n```json\n{\n  \"ava\": {\n     \"babel\": {\n       \"presets\": [\n          \"es2015\",\n          \"stage-0\",\n          \"react\"\n       ]\n     }\n  }\n}\n```\n\nYou can also use the special `\"inherit\"` keyword. This makes AVA defer to the Babel config in your [`.babelrc` or `package.json` file](https://babeljs.io/docs/usage/babelrc/). This way your test files will be transpiled using the same config as your source files without having to repeat it just for AVA:\n\n```json\n{\n  \"babel\": {\n    \"presets\": [\n      \"es2015\",\n      \"stage-0\",\n      \"react\"\n    ]\n  },\n  \"ava\": {\n    \"babel\": \"inherit\"\n  }\n}\n```\n\nSee AVA's [`.babelrc` recipe](docs/recipes/babelrc.md) for further examples and a more detailed explanation of configuration options.\n\nNote that AVA will *always* apply [a few internal plugins](docs/recipes/babelrc.md#notes) regardless of configuration, but they should not impact the behavior of your code.\n\n### TypeScript support\n\nAVA includes typings for TypeScript. You have to set up transpilation yourself. When you set `module` to `commonjs` in your `tsconfig.json` file, TypeScript will automatically find the type definitions for AVA. You should set `target` to `es2015` to use promises and async functions.\n\nSee AVA's [TypeScript recipe](docs/recipes/typescript.md) for a more detailed explanation.\n\n### Transpiling imported modules\n\nAVA currently only transpiles the tests you ask it to run, as well as test helpers (files starting with `_` or in `helpers` directory) inside the test directory. *It will not transpile modules you `import` from outside of the test.* This may be unexpected but there are workarounds.\n\nIf you use Babel you can use its [require hook](https://babeljs.io/docs/usage/require/) to transpile imported modules on-the-fly. To add it, [configure it in your `package.json`](#configuration).\n\nYou can also transpile your modules in a separate process and refer to the transpiled files rather than the sources from your tests. Example [here](docs/recipes/precompiling-with-webpack.md).\n\n### Promise support\n\nIf you return a promise in the test you don't need to explicitly end the test as it will end when the promise resolves.\n\n```js\ntest(t => {\n\treturn somePromise().then(result => {\n\t\tt.is(result, 'unicorn');\n\t});\n});\n```\n\n### Generator function support\n\nAVA comes with built-in support for [generator functions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/function*).\n\n```js\ntest(function * (t) {\n\tconst value = yield generatorFn();\n\tt.true(value);\n});\n```\n\n### Async function support\n\nAVA comes with built-in support for [async functions](https://tc39.github.io/ecmascript-asyncawait/) *(async/await)*.\n\n```js\ntest(async function (t) {\n\tconst value = await promiseFn();\n\tt.true(value);\n});\n\n// Async arrow function\ntest(async t => {\n\tconst value = await promiseFn();\n\tt.true(value);\n});\n```\n\n### Observable support\n\nAVA comes with built-in support for [observables](https://github.com/zenparsing/es-observable). If you return an observable from a test, AVA will automatically consume it to completion before ending the test.\n\n*You do not need to use \"callback mode\" or call `t.end()`.*\n\n```js\ntest(t => {\n\tt.plan(3);\n\treturn Observable.of(1, 2, 3, 4, 5, 6)\n\t\t.filter(n => {\n\t\t\t// Only even numbers\n\t\t\treturn n % 2 === 0;\n\t\t})\n\t\t.map(() => t.pass());\n});\n```\n\n### Callback support\n\nAVA supports using `t.end` as the final callback when using node-style error-first callback APIs. AVA will consider any truthy value passed as the first argument to `t.end` to be an error. Note that `t.end` requires \"callback mode\", which can be enabled by using the `test.cb` chain.\n\n```js\ntest.cb(t => {\n\t// `t.end` automatically checks for error as first argument\n\tfs.readFile('data.txt', t.end);\n});\n```\n\n### Global timeout\n\nA global timeout can be set via the `--timeout` option.\nTimeout in AVA behaves differently than in other test frameworks.\nAVA resets a timer after each test, forcing tests to quit if no new test results were received within the specified timeout.\n\nYou can set timeouts in a human-readable way:\n\n```console\n$ ava --timeout=10s # 10 seconds\n$ ava --timeout=2m # 2 minutes\n$ ava --timeout=100 # 100 milliseconds\n```\n\n## API\n\n### `test([title], implementation)`\n### `test.serial([title], implementation)`\n### `test.cb([title], implementation)`\n### `test.only([title], implementation)`\n### `test.skip([title], implementation)`\n### `test.todo(title)`\n### `test.failing([title], implementation)`\n### `test.before([title], implementation)`\n### `test.after([title], implementation)`\n### `test.beforeEach([title], implementation)`\n### `test.afterEach([title], implementation)`\n\n#### `title`\n\nType: `string`\n\nTest title.\n\n#### `implementation(t)`\n\nType: `function`\n\nShould contain the actual test.\n\n##### `t`\n\nType: `object`\n\nThe execution object of a particular test. Each test implementation receives a different object. Contains the [assertions](#assertions) as well as `.plan(count)` and `.end()` methods. `t.context` can contain shared state from `beforeEach` hooks.\n\n###### `t.plan(count)`\n\nPlan how many assertion there are in the test. The test will fail if the actual assertion count doesn't match the number of planned assertions. See [assertion planning](#assertion-planning).\n\n###### `t.end()`\n\nEnd the test. Only works with `test.cb()`.\n\n## Assertions\n\nAssertions are mixed into the [execution object](#t) provided to each test implementation:\n\n```js\ntest(t => {\n\tt.truthy('unicorn'); // Assertion\n});\n```\n\nIf multiple assertion failures are encountered within a single test, AVA will only display the *first* one.\n\n### `.pass([message])`\n\nPassing assertion.\n\n### `.fail([message])`\n\nFailing assertion.\n\n### `.truthy(value, [message])`\n\nAssert that `value` is truthy.\n\n### `.falsy(value, [message])`\n\nAssert that `value` is falsy.\n\n### `.true(value, [message])`\n\nAssert that `value` is `true`.\n\n### `.false(value, [message])`\n\nAssert that `value` is `false`.\n\n### `.is(value, expected, [message])`\n\nAssert that `value` is equal to `expected`.\n\n### `.not(value, expected, [message])`\n\nAssert that `value` is not equal to `expected`.\n\n### `.deepEqual(value, expected, [message])`\n\nAssert that `value` is deep equal to `expected`. This is based on [Lodash' `isEqual()`](https://lodash.com/docs/4.17.4#isEqual):\n\n> Performs a deep comparison between two values to determine if they are equivalent.\n>\n> *Note*: This method supports comparing arrays, array buffers, booleans, date objects, error objects, maps, numbers, `Object` objects, regexes, sets, strings, symbols, and typed arrays. `Object` objects are compared by their own, not inherited, enumerable properties. Functions and DOM nodes are compared by strict equality, i.e. `===`.\n\n### `.notDeepEqual(value, expected, [message])`\n\nAssert that `value` is not deep equal to `expected`. The inverse of `.deepEqual()`.\n\n### `.throws(function|promise, [error, [message]])`\n\nAssert that `function` throws an error, or `promise` rejects with an error.\n\n`error` can be an error constructor, error message, regex matched against the error message, or validation function.\n\nReturns the error thrown by `function` or a promise for the rejection reason of the specified `promise`.\n\nExample:\n\n```js\nconst fn = () => {\n\tthrow new TypeError('ðŸ¦„');\n};\n\ntest('throws', t => {\n\tconst error = t.throws(() => {\n\t\tfn();\n\t}, TypeError);\n\n\tt.is(error.message, 'ðŸ¦„');\n});\n```\n\n```js\nconst promise = Promise.reject(new TypeError('ðŸ¦„'));\n\ntest('rejects', async t => {\n\tconst error = await t.throws(promise);\n\tt.is(error.message, 'ðŸ¦„');\n});\n```\n\nWhen testing a promise you must wait for the assertion to complete:\n\n```js\ntest('rejects', async t => {\n\tawait t.throws(promise);\n});\n```\n\n### `.notThrows(function|promise, [message])`\n\nAssert that `function` does not throw an error or that `promise` does not reject with an error.\n\nLike the `.throws()` assertion, when testing a promise you must wait for the assertion to complete:\n\n```js\ntest('rejects', async t => {\n\tawait t.notThrows(promise);\n});\n```\n\n### `.regex(contents, regex, [message])`\n\nAssert that `contents` matches `regex`.\n\n### `.notRegex(contents, regex, [message])`\n\nAssert that `contents` does not match `regex`.\n\n### `.ifError(error, [message])`\n\nAssert that `error` is falsy.\n\n### `.snapshot(contents, [message])`\n\nMake a snapshot of the stringified `contents`.\n\n## Snapshot testing\n\nSnapshot testing comes as another kind of assertion and uses [jest-snapshot](https://facebook.github.io/jest/blog/2016/07/27/jest-14.html) under the hood.\n\nWhen used with React, it looks very similar to Jest:\n\n```js\n// Your component\nconst HelloWorld = () => <h1>Hello World...!</h1>;\n\nexport default HelloWorld;\n```\n\n```js\n// Your test\nimport test from 'ava';\nimport render from 'react-test-renderer';\n\nimport HelloWorld from '.';\n\ntest('HelloWorld component', t => {\n\tconst tree = render.create(<HelloWorld />).toJSON();\n\tt.snapshot(tree);\n});\n```\n\nThe first time you run this test, a snapshot file will be created in `__snapshots__` folder looking something like this:\n\n```js\nexports[`HelloWorld component 1`] = `\n<h1>\n\tHello World...!\n</h1>\n`;\n```\n\nThese snapshots should be committed together with your code so that everyone on the team shares current state of the app.\n\nEvery time you run this test afterwards, it will check if the component render has changed. If it did, it will fail the test.\n\n<img src=\"media/snapshot-testing.png\" width=\"814\">\n\nThen you will have the choice to check your code - and if the change was intentional, you can use the `--update-snapshots` (or `-u`) flag to update the snapshots into their new version.\n\nThat might look like this:\n\n```console\n$ ava --update-snapshots\n```\n\nNote that snapshots can be used for much more than just testing components - you can equally well test any other (data) structure that you can stringify.\n\n### Skipping assertions\n\nAny assertion can be skipped using the `skip` modifier. Skipped assertions are still counted, so there is no need to change your planned assertion count.\n\n```js\ntest(t => {\n\tt.plan(2);\n\tt.skip.is(foo(), 5); // No need to change your plan count when skipping\n\tt.is(1, 1);\n});\n```\n\n### Enhanced assertion messages\n\nAVA comes with [`power-assert`](https://github.com/power-assert-js/power-assert) built-in, giving you more descriptive assertion messages. It reads your test and tries to infer more information from the code.\n\nLet's take this example, using Node's standard [`assert` library](https://nodejs.org/api/assert.html):\n\n```js\nconst a = /foo/;\nconst b = 'bar';\nconst c = 'baz';\nrequire('assert').ok(a.test(b) || b === c);\n```\n\nIf you paste that into a Node REPL it'll return:\n\n```\nAssertionError: false == true\n```\n\nIn AVA however, this test:\n\n```js\ntest(t => {\n\tconst a = /foo/;\n\tconst b = 'bar';\n\tconst c = 'baz';\n\tt.true(a.test(b) || b === c);\n});\n```\n\nWill output:\n\n```\nt.true(a.test(b) || b === c)\n       |      |     |     |\n       |      \"bar\" \"bar\" \"baz\"\n       false\n```\n\n## Process isolation\n\nEach test file is run in a separate Node.js process. This allows you to change the global state or overriding a built-in in one test file, without affecting another. It's also great for performance on modern multi-core processors, allowing multiple test files to execute in parallel.\n\n## Tips\n\n### Temp files\n\nRunning tests concurrently comes with some challenges, doing file IO is one.\n\nUsually, serial tests create temp directories in the current test directory and clean them up at the end. This won't work when you run tests concurrently as tests will conflict with each other. The correct way to do it is to use a new temp directory for each test. The [`tempfile`](https://github.com/sindresorhus/tempfile) and [`temp-write`](https://github.com/sindresorhus/temp-write) modules can be helpful.\n\n### Code coverage\n\nYou can't use [`istanbul`](https://github.com/gotwarlost/istanbul) for code coverage as AVA [spawns the test files](#process-isolation). You can use [`nyc`](https://github.com/bcoe/nyc) instead, which is basically `istanbul` with support for subprocesses.\n\nAs of version `5.0.0` it uses source maps to report coverage for your actual code, regardless of transpilation. Make sure that the code you're testing includes an inline source map or references a source map file. If you use `babel-register` you can set the `sourceMaps` option in your Babel config to `inline`.\n\n### Common pitfalls\n\nWe have a growing list of [common pitfalls](docs/common-pitfalls.md) you may experience while using AVA. If you encounter any issues you think are common, comment in [this issue](https://github.com/avajs/ava/issues/404).\n\n## FAQ\n\n### Why not `mocha`, `tape`, `tap`?\n\nMocha requires you to use implicit globals like `describe` and `it` with the default interface (which most people use). It's not very opinionated and executes tests serially without process isolation, making it slow.\n\nTape and tap are pretty good. AVA is highly inspired by their syntax. They too execute tests serially. Their default [TAP](https://testanything.org) output isn't very user-friendly though so you always end up using an external tap reporter.\n\nIn contrast AVA is highly opinionated and runs tests concurrently, with a separate process for each test file. Its default reporter is easy on the eyes and yet AVA still supports TAP output through a CLI flag.\n\n### How is the name written and pronounced?\n\nAVA, not Ava or ava. Pronounced [`/ËˆeÉªvÉ™/` ay-vÉ™](media/pronunciation.m4a?raw=true).\n\n### What is the header background?\n\nIt's the [Andromeda galaxy](https://simple.wikipedia.org/wiki/Andromeda_galaxy).\n\n### What is the difference between concurrency and parallelism?\n\n[Concurrency is not parallelism. It enables parallelism.](https://stackoverflow.com/q/1050222)\n\n## Recipes\n\n- [Code coverage](docs/recipes/code-coverage.md)\n- [Watch mode](docs/recipes/watch-mode.md)\n- [Endpoint testing](docs/recipes/endpoint-testing.md)\n- [When to use `t.plan()`](docs/recipes/when-to-use-plan.md)\n- [Browser testing](docs/recipes/browser-testing.md)\n- [TypeScript](docs/recipes/typescript.md)\n- [Configuring Babel](docs/recipes/babelrc.md)\n- [Testing React components](docs/recipes/react.md)\n- [JSPM and SystemJS](docs/recipes/jspm-systemjs.md)\n- [Debugging tests with Chrome DevTools](docs/recipes/debugging-with-chrome-devtools.md)\n- [Debugging tests with WebStorm](docs/recipes/debugging-with-webstorm.md)\n- [Precompiling source files with webpack](docs/recipes/precompiling-with-webpack.md)\n\n## Support\n\n- [Stack Overflow](https://stackoverflow.com/questions/tagged/ava)\n- [Gitter chat](https://gitter.im/avajs/ava)\n- [Twitter](https://twitter.com/ava__js)\n\n## Related\n\n- [eslint-plugin-ava](https://github.com/avajs/eslint-plugin-ava) - Lint rules for AVA tests\n- [sublime-ava](https://github.com/avajs/sublime-ava) - Snippets for AVA tests\n- [atom-ava](https://github.com/avajs/atom-ava) - Snippets for AVA tests\n- [vscode-ava](https://github.com/samverschueren/vscode-ava) - Snippets for AVA tests\n- [gulp-ava](https://github.com/avajs/gulp-ava) - Run tests with gulp\n- [grunt-ava](https://github.com/avajs/grunt-ava) - Run tests with grunt\n- [Moreâ€¦](https://github.com/avajs/awesome-ava#packages)\n\n## Links\n\n- [Buy AVA stickers](https://www.stickermule.com/user/1070705604/stickers)\n- [Awesome list](https://github.com/avajs/awesome-ava)\n- [AVA Casts](http://avacasts.com)\n- [Moreâ€¦](https://github.com/avajs/awesome-ava)\n\n## Team\n\n[![Sindre Sorhus](https://avatars.githubusercontent.com/u/170270?s=130)](http://sindresorhus.com) | [![Vadim Demedes](https://avatars.githubusercontent.com/u/697676?s=130)](https://github.com/vadimdemedes) | [![James Talmage](https://avatars.githubusercontent.com/u/4082216?s=130)](https://github.com/jamestalmage) | [![Mark Wubben](https://avatars.githubusercontent.com/u/33538?s=130)](https://novemberborn.net) | [![Juan Soto](https://avatars.githubusercontent.com/u/8217766?s=130)](https://juansoto.me) | [![Jeroen Engels](https://avatars.githubusercontent.com/u/3869412?s=130)](https://github.com/jfmengels)\n---|---|---|---|---|---\n[Sindre Sorhus](http://sindresorhus.com) | [Vadim Demedes](https://github.com/vadimdemedes) | [James Talmage](https://github.com/jamestalmage) | [Mark Wubben](https://novemberborn.net) | [Juan Soto](http://juansoto.me) | [Jeroen Engels](https://github.com/jfmengels)\n\n### Former\n\n- [Kevin MÃ¥rtensson](https://github.com/kevva)\n\n\n<div align=\"center\">\n\t<br>\n\t<br>\n\t<br>\n\t<a href=\"https://ava.li\">\n\t\t<img src=\"https://cdn.rawgit.com/avajs/ava/fe1cea1ca3d2c8518c0cc39ec8be592beab90558/media/logo.svg\" width=\"200\" alt=\"AVA\">\n\t</a>\n\t<br>\n\t<br>\n</div>\n",
  "readmeFilename": "readme.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/avajs/ava.git"
  },
  "scripts": {
    "make-ts": "node types/make.js",
    "prepublish": "npm run make-ts",
    "test": "xo && flow check test/flow-types && tsc -p test/ts-types && nyc tap --no-cov --timeout=150 --jobs=4 test/*.js test/reporters/*.js",
    "test-win": "tap --no-cov --reporter=classic --timeout=150 --jobs=4 test/*.js test/reporters/*.js",
    "visual": "node test/visual/run-visual-tests.js"
  },
  "typings": "types/generated.d.ts",
  "version": "0.19.1",
  "xo": {
    "esnext": true,
    "rules": {
      "import/newline-after-import": "off",
      "no-use-extend-native/no-use-extend-native": "off"
    }
  }
}
